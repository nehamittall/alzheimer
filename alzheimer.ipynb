{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2 \nimport os\nfrom matplotlib import pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms, io, models\nimport os\nimport random\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2022-08-23T00:47:44.580287Z","iopub.execute_input":"2022-08-23T00:47:44.580993Z","iopub.status.idle":"2022-08-23T00:47:46.989855Z","shell.execute_reply.started":"2022-08-23T00:47:44.580912Z","shell.execute_reply":"2022-08-23T00:47:46.988701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_images(imges):\n  fig = plt.figure(figsize=(10, 5))\n  rows = 1\n  columns = 10\n  for i,img in enumerate(imges):\n    fig.add_subplot(rows, columns, i+1)\n    plt.imshow(img)\n  plt.show(block = True)","metadata":{"execution":{"iopub.status.busy":"2022-08-23T00:47:50.248698Z","iopub.execute_input":"2022-08-23T00:47:50.252291Z","iopub.status.idle":"2022-08-23T00:47:50.280561Z","shell.execute_reply.started":"2022-08-23T00:47:50.249416Z","shell.execute_reply":"2022-08-23T00:47:50.279321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AlDataset(torch.utils.data.Dataset):\n\n  def __init__(self, train_dir, transforms = None):\n    super().__init__()\n    self.train_dir = train_dir\n    self.transforms = transforms\n    self.train_images = []\n    self.read_data()\n\n   \n\n  def __len__(self):\n    return len(self.train_images)\n\n  def __getitem__(self, idx):\n    return {'image': self.transforms(io.read_image(self.train_images[idx]['image']).repeat(3,1,1)) , 'label': self.train_images[idx]['label']}\n  \n  def read_data(self):\n\n      self.labels = os.listdir(self.train_dir)\n\n      for i, subdir in enumerate(self.labels):\n        images = os.listdir(self.train_dir + '/' + subdir)\n        for img in images:\n          data = {}\n          data['image'] = self.train_dir + '/' + subdir + '/' + img\n          data['label'] = i\n          self.train_images.append(data)\n        \n      \n      random.shuffle(self.train_images)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-23T00:50:26.823852Z","iopub.execute_input":"2022-08-23T00:50:26.824233Z","iopub.status.idle":"2022-08-23T00:50:26.833332Z","shell.execute_reply.started":"2022-08-23T00:50:26.824202Z","shell.execute_reply":"2022-08-23T00:50:26.832173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"commented this piece of code as it was used to generate the mean & standard deviation of the dataset for normalizing the dataset","metadata":{}},{"cell_type":"code","source":"# psum    = torch.tensor([0.0, 0.0, 0.0])\n# psum_sq = torch.tensor([0.0, 0.0, 0.0])\n\n\n# for i, batch in enumerate(trainLoader): \n#     _batch, labels = batch['image'], batch['label']\n    \n#     psum    += _batch.sum(axis = [ 0, 2, 3])\n#     psum_sq += (_batch ** 2).sum(axis = [0, 2, 3])\n    \n# count = trainDataset.__len__() * 208 * 176\n\n# # mean and std\n# total_mean = psum / count\n# total_var  = (psum_sq / count) - (total_mean ** 2)\n# total_std  = torch.sqrt(total_var)\n\n# # output\n# print('mean: '  + str(total_mean))\n# print('std:  '  + str(total_std))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainDataset = AlDataset('/kaggle/input/alzeihmer/Alzheimer_s Dataset/train', transforms = transforms.Compose([\n                                    transforms.ConvertImageDtype(torch.float), \n                                    transforms.\n                                    transforms.Normalize([0.2821, 0.2821,0.2821], [0.3258, 0.3258, 0.3258])\n                                        ]))\ntestDataset = AlDataset('/kaggle/input/alzeihmer/Alzheimer_s Dataset/test' , transforms = transforms.Compose([\n                                    transforms.ConvertImageDtype(torch.float),\n                                    transforms.Normalize([0.2821], [0.3258])\n                                        ]))","metadata":{"execution":{"iopub.status.busy":"2022-08-23T00:50:30.114016Z","iopub.execute_input":"2022-08-23T00:50:30.114408Z","iopub.status.idle":"2022-08-23T00:50:30.141242Z","shell.execute_reply.started":"2022-08-23T00:50:30.114373Z","shell.execute_reply":"2022-08-23T00:50:30.140388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader","metadata":{"execution":{"iopub.status.busy":"2022-08-23T00:50:33.525406Z","iopub.execute_input":"2022-08-23T00:50:33.525772Z","iopub.status.idle":"2022-08-23T00:50:33.531046Z","shell.execute_reply.started":"2022-08-23T00:50:33.525743Z","shell.execute_reply":"2022-08-23T00:50:33.529912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainLoader = DataLoader(dataset = trainDataset, batch_size = 256, num_workers = 2, shuffle = True)\ntestLoader = DataLoader(dataset = testDataset, batch_size = 128)","metadata":{"execution":{"iopub.status.busy":"2022-08-23T00:50:37.446175Z","iopub.execute_input":"2022-08-23T00:50:37.446549Z","iopub.status.idle":"2022-08-23T00:50:37.451979Z","shell.execute_reply.started":"2022-08-23T00:50:37.446517Z","shell.execute_reply":"2022-08-23T00:50:37.451063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AlNet(nn.Module):\n    def __init__(self, num_classes=4):\n      super().__init__()\n      self.net = nn.Sequential(\n          \n          #initial 208 X 176 X 1\n          \n          nn.Conv2d(in_channels = 3, out_channels = 48 , kernel_size = 11, stride = 2),  # 99 X 83 X 48\n          nn.ReLU(),\n          nn.MaxPool2d(kernel_size=2, stride=2),                                         # 49 X 41 X 48\n          nn.BatchNorm2d(48),\n          \n          nn.Conv2d(in_channels=48, out_channels=128, kernel_size=5, padding=1),         # 47 X 39 X 128\n          nn.ReLU(),\n          nn.MaxPool2d(kernel_size=2,stride=2),                                          # 23 X 19 X 128\n          nn.BatchNorm2d(128)\n      )\n\n      self.fc = nn.Sequential(\n          nn.Linear(in_features=(23 * 19 * 128), out_features=1024),\n          nn.ReLU(),\n          nn.Dropout(p=0.5,),\n          nn.Linear(in_features=1024, out_features=512),\n          nn.ReLU(),\n          nn.Linear(in_features=512, out_features=num_classes),\n      )\n    \n      self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, input):\n      input = self.net(input)\n      input = torch.flatten(input, start_dim=1)\n      input = self.fc(input)\n      input = self.softmax(input)\n      return input\n","metadata":{"execution":{"iopub.status.busy":"2022-08-23T00:50:42.917550Z","iopub.execute_input":"2022-08-23T00:50:42.918030Z","iopub.status.idle":"2022-08-23T00:50:42.930566Z","shell.execute_reply.started":"2022-08-23T00:50:42.917987Z","shell.execute_reply":"2022-08-23T00:50:42.929462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\n\nalnet = AlNet().to(device)\n\noptimizer = optim.Adam(params=alnet.parameters(), lr=0.0001)\n\n# Set Loss function with criterion\ncriterion = nn.CrossEntropyLoss()\n\n # multiply LR by 1 / 10 after every 20 epochs\nlr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2022-08-23T00:50:47.852110Z","iopub.execute_input":"2022-08-23T00:50:47.852516Z","iopub.status.idle":"2022-08-23T00:50:51.239892Z","shell.execute_reply.started":"2022-08-23T00:50:47.852482Z","shell.execute_reply":"2022-08-23T00:50:51.238924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_classes = 4\nlearning_rate = 0.001\nnum_epochs = 25","metadata":{"execution":{"iopub.status.busy":"2022-08-23T00:51:01.324751Z","iopub.execute_input":"2022-08-23T00:51:01.325396Z","iopub.status.idle":"2022-08-23T00:51:01.330126Z","shell.execute_reply.started":"2022-08-23T00:51:01.325328Z","shell.execute_reply":"2022-08-23T00:51:01.328897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Starting Training ....')\ntotal_count = 0\ntotal_correct = 0\n\nalnet.train()\nfor epoch in range(num_epochs):\n  lr_scheduler.step()\n  for i, batch in enumerate(trainLoader): \n        \n      batch, labels = batch['image'].to(device), batch['label'].to(device)\n\n      output = alnet(batch)\n      loss = criterion(output, labels)\n\n      optimizer.zero_grad()\n      loss.backward()\n      optimizer.step()\n\n      total_count += len(batch)\n      _, preds = torch.max(output, 1)\n      total_correct += torch.sum(preds == labels).sum().item()\n\n\n\n  print('Epoch %d/%d Accuracy %0.4f ' % ( epoch, num_epochs, (total_correct/total_count)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Starting Testing...')\ntotal_count = 0\ntotal_correct = 0\n\nalnet.eval()\n\nfor i, batch in enumerate(testLoader): \n    batch, labels = batch['image'].to(device), batch['label'].to(device)\n\n    output = alnet(batch)\n\n    total_count += len(batch)\n    _, preds = torch.max(output, 1)\n    total_correct += torch.sum(preds == labels).sum().item()\n\n    print(' Accuracy %0.4f ' % ((total_correct/total_count)))","metadata":{"execution":{"iopub.status.busy":"2022-08-20T01:50:42.037841Z","iopub.execute_input":"2022-08-20T01:50:42.038161Z","iopub.status.idle":"2022-08-20T01:50:42.044006Z","shell.execute_reply.started":"2022-08-20T01:50:42.038136Z","shell.execute_reply":"2022-08-20T01:50:42.043121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transfer Learning #\n","metadata":{}},{"cell_type":"code","source":"class MyMaxPool(nn.Module):\n    \n    def __init__(self):\n        super(MyMaxPool, self).__init__()\n        \n    def forward(self, x):\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-08-20T01:50:42.047276Z","iopub.execute_input":"2022-08-20T01:50:42.047532Z","iopub.status.idle":"2022-08-20T01:50:42.054036Z","shell.execute_reply.started":"2022-08-20T01:50:42.047509Z","shell.execute_reply":"2022-08-20T01:50:42.053035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision import models\n\n\nmodel =  models.vgg16(pretrained=False)\n\nmodel.avgpool = MyMaxPool()\nmodel.classifier = nn.Sequential(nn.Linear(15360, 4096), \n                                 nn.ReLU(), \n                                 nn.Dropout(0.5),\n                                 nn.Linear(4096, 4096),\n                                 nn.ReLU(), \n                                 nn.Dropout(0.5),\n                                 nn.Linear(4096, 4)\n                                )","metadata":{"execution":{"iopub.status.busy":"2022-08-20T01:50:42.055677Z","iopub.execute_input":"2022-08-20T01:50:42.056049Z","iopub.status.idle":"2022-08-20T01:50:45.173602Z","shell.execute_reply.started":"2022-08-20T01:50:42.056015Z","shell.execute_reply":"2022-08-20T01:50:45.172626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\n\n\noptimizer = optim.Adam(params=model.parameters(), lr=0.0001)\n\n# Set Loss function with criterion\ncriterion = nn.CrossEntropyLoss()\n\n # multiply LR by 1 / 10 after every 20 epochs\nlr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n\nfor param in model.parameters:\n    ","metadata":{"execution":{"iopub.status.busy":"2022-08-20T02:08:16.016775Z","iopub.execute_input":"2022-08-20T02:08:16.017180Z","iopub.status.idle":"2022-08-20T02:08:16.027019Z","shell.execute_reply.started":"2022-08-20T02:08:16.017139Z","shell.execute_reply":"2022-08-20T02:08:16.025270Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Starting Training ....')\ntotal_count = 0\ntotal_correct = 0\nmodel.to(device)\nmodel.train()\nfor epoch in range(num_epochs):\n    for i, batch in enumerate(trainLoader): \n        \n        batch, labels = batch['image'].to(device), batch['label'].to(device)\n        output = model(batch)\n        loss = criterion(output, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        total_count += len(batch)\n        _, preds = torch.max(output, 1)\n        total_correct += torch.sum(preds == labels).sum().item()\n    print('Epoch %d/%d Accuracy %0.4f ' % ( epoch, num_epochs, (total_correct/total_count)))","metadata":{"execution":{"iopub.status.busy":"2022-08-20T01:50:48.168159Z","iopub.execute_input":"2022-08-20T01:50:48.168542Z","iopub.status.idle":"2022-08-20T02:08:15.163854Z","shell.execute_reply.started":"2022-08-20T01:50:48.168505Z","shell.execute_reply":"2022-08-20T02:08:15.162723Z"},"trusted":true},"execution_count":null,"outputs":[]}]}